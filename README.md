## Cross-modal-retrieval
Our approach is focus on Activity Image-to-Video Retrieval (AIVR) task. 
The compared methods are state-of-the-art single modality hashing methods, multiple modalities
hashing methods and cross-modal retrieval methods.

#### **Single modality hashing methods**
Some hashing baselines for image retrieval can be found in <https://github.com/willard-yuan/hashing-baseline-for-image-retrieval>.
#### **Multiple modalities hashing methods**
More details refer to <https://github.com/czxxjtu/Hash-Learning.github.io>.
Some details about hashing methods are in hashing-baseline-for-image-retrieval-master folder.
#### **Cross-modal retrieval methods**
The compared cross-modal retrieval methods are according to the paper:
#### **Datasets**
##### THUMOS'14 Dataset:
https://pan.baidu.com/s/1H6c8nh_Hs7gVkhESpxtvAg 
提取码：qp26 

##### ActivityNet Dataset:
https://pan.baidu.com/s/1P0jRecEmplCPaTPwFoOpVQ 
提取码：pnw9

#### **Bibtex**
When using images from our dataset, please cite our paper using the following BibTeX[[PDF]](https://arxiv.org/abs/1911.10531)：
```
@article{pba2020,
author    = {Ruicong Xu and Li Niu and Jianfu Zhang and Liqing Zhang},
title     = {A Proposal-based Approach for Activity Image-to-Video Retrieval},
journal   = {AAAI},
year      = {2020}}
```
